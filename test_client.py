#!/usr/bin/env python3
"""
RunPod Serverless Demo Client with Performance Metrics
Pour impressionner les devs avec des r√©sultats concrets
"""

import runpod
import time
import json
import sys
from datetime import datetime

class RunPodDemoClient:
    def __init__(self, api_key, endpoint_id):
        self.api_key = api_key
        self.endpoint_id = endpoint_id
        runpod.api_key = api_key
        
        print("üöÄ RunPod Serverless Demo Client")
        print(f"   Endpoint: {endpoint_id}")
        print(f"   Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("-" * 60)
    
    def run_single_test(self, test_name, prompt, expected_duration=None):
        """Run a single test case with detailed metrics"""
        
        print(f"\nüìã {test_name}")
        print(f"   Prompt: {prompt[:80]}...")
        
        # Prepare job input
        job_input = {
            "prompt": prompt,
            "workflow_type": "wan-t2v",
            "seed": int(time.time())
        }
        
        # Submit job
        submit_start = time.time()
        try:
            job = runpod.run({"input": job_input}, endpoint_id=self.endpoint_id)
            job_id = job['id']
            submit_time = time.time() - submit_start
            print(f"   ‚úÖ Job submitted in {submit_time:.2f}s - ID: {job_id}")
        except Exception as e:
            print(f"   ‚ùå Submission failed: {e}")
            return None
        
        # Wait for completion
        total_start = time.time()
        last_status = ""
        
        while True:
            try:
                status = runpod.get_job(job_id, self.endpoint_id)
                current_status = status.get('status', 'UNKNOWN')
                elapsed = time.time() - total_start
                
                # Update status if changed
                if current_status != last_status:
                    print(f"   üìä Status: {current_status} ({elapsed:.0f}s)")
                    last_status = current_status
                
                if current_status == 'COMPLETED':
                    output = status.get('output', {})
                    return self.process_success(output, elapsed)
                    
                elif current_status in ['FAILED', 'CANCELLED']:
                    error_msg = status.get('error', 'Unknown error')
                    print(f"   ‚ùå Job failed: {error_msg}")
                    return None
                
                elif elapsed > 300:  # 5 minute timeout
                    print(f"   ‚è∞ Timeout after {elapsed:.0f}s")
                    return None
                
                time.sleep(5)
                
            except Exception as e:
                print(f"   ‚ùå Polling error: {e}")
                time.sleep(10)
    
    def process_success(self, output, total_elapsed):
        """Process successful job output and extract metrics"""
        
        metrics = output.get('metrics', {})
        infrastructure = output.get('infrastructure', {})
        outputs = output.get('outputs', [])
        
        # Display results
        print(f"   ‚úÖ COMPLETED!")
        print(f"   üìä Performance Metrics:")
        print(f"      Cold Start: {metrics.get('cold_start_seconds', 0)}s")
        print(f"      ComfyUI Boot: {metrics.get('comfy_boot_seconds', 0)}s") 
        print(f"      Processing: {metrics.get('processing_seconds', 0)}s")
        print(f"      Total: {metrics.get('total_seconds', total_elapsed):.1f}s")
        print(f"      Cost Estimate: ${metrics.get('cost_estimate_usd', 0):.4f}")
        
        print(f"   üñ•Ô∏è  Infrastructure:")
        print(f"      GPU: {infrastructure.get('gpu_type', 'Unknown')}")
        print(f"      Worker: {infrastructure.get('worker_id', 'Unknown')}")
        
        print(f"   üìÅ Outputs: {len(outputs)} files")
        for output_file in outputs:
            print(f"      {output_file.get('type', 'file')}: {output_file.get('filename', 'unknown')}")
        
        return {
            'success': True,
            'total_time': total_elapsed,
            'metrics': metrics,
            'infrastructure': infrastructure,
            'outputs': outputs
        }
    
    def run_benchmark_suite(self):
        """Run complete benchmark suite"""
        
        test_cases = [
            {
                "name": "Test 1: Basic NSFW Generation",
                "prompt": "Beautiful woman dancing sensually, high quality, 4K",
                "expected": "2-3 minutes"
            },
            {
                "name": "Test 2: Action Movement",
                "prompt": "Dynamic woman in motion, NSFW content, professional quality",
                "expected": "2-3 minutes" 
            },
            {
                "name": "Test 3: Complex Scene",
                "prompt": "Multiple people, NSFW scene, cinematic lighting, ultra detailed",
                "expected": "3-4 minutes"
            }
        ]
        
        print("\nüéØ Running Full Benchmark Suite")
        print(f"   Tests: {len(test_cases)}")
        print(f"   Expected total time: 6-10 minutes")
        
        results = []
        suite_start = time.time()
        
        for i, test in enumerate(test_cases, 1):
            print(f"\n{'='*60}")
            print(f"Running Test {i}/{len(test_cases)}")
            
            result = self.run_single_test(
                test["name"],
                test["prompt"], 
                test["expected"]
            )
            
            if result:
                results.append(result)
            else:
                print(f"   ‚ö†Ô∏è  Test {i} failed or timed out")
        
        # Summary
        suite_time = time.time() - suite_start
        self.print_summary(results, suite_time)
        
        return results
    
    def print_summary(self, results, suite_time):
        """Print comprehensive benchmark summary"""
        
        if not results:
            print("\n‚ùå No successful tests to summarize")
            return
        
        print(f"\n{'='*60}")
        print("üìä DEMO BENCHMARK SUMMARY")
        print(f"{'='*60}")
        
        # Overall stats
        success_count = len(results)
        avg_cold_start = sum(r['metrics'].get('cold_start_seconds', 0) for r in results) / success_count
        avg_processing = sum(r['metrics'].get('processing_seconds', 0) for r in results) / success_count
        avg_total = sum(r['total_time'] for r in results) / success_count
        total_cost = sum(r['metrics'].get('cost_estimate_usd', 0) for r in results)
        
        print(f"‚úÖ Tests completed: {success_count}")
        print(f"‚è±Ô∏è  Suite duration: {suite_time:.1f}s ({suite_time/60:.1f} min)")
        print(f"üöÄ Avg cold start: {avg_cold_start:.1f}s")
        print(f"‚ö° Avg processing: {avg_processing:.1f}s") 
        print(f"üìä Avg total time: {avg_total:.1f}s")
        print(f"üí∞ Total cost: ${total_cost:.4f}")
        
        # GPU info (from first successful test)
        if results:
            gpu_type = results[0]['infrastructure'].get('gpu_type', 'Unknown')
            print(f"üñ•Ô∏è  GPU Type: {gpu_type}")
        
        # Cost projection
        daily_jobs = 100
        monthly_cost = total_cost * (daily_jobs / success_count) * 30
        print(f"\nüí° Cost Projections:")
        print(f"   {daily_jobs} jobs/day: ${monthly_cost:.2f}/month")
        
        # Compare with 24/7 pod
        gpu_hourly_rates = {
            "RTX 4090 PRO": 0.50,
            "RTX 4090": 0.50,
            "L4": 0.30,
            "A100": 0.80
        }
        
        hourly_rate = gpu_hourly_rates.get(gpu_type, 0.50)
        pod_monthly_cost = hourly_rate * 24 * 30
        savings = pod_monthly_cost - monthly_cost
        savings_percent = (savings / pod_monthly_cost) * 100
        
        print(f"   24/7 {gpu_type} Pod: ${pod_monthly_cost:.2f}/month")
        print(f"   üíµ Savings: ${savings:.2f}/month ({savings_percent:.0f}%)")
        
        print(f"\nüéâ Demo Results: SERVERLESS IS {savings_percent:.0f}% CHEAPER!")
        
        # Recommendations for devs
        print(f"\nüí° Recommendations for Production:")
        print(f"   ‚Ä¢ Use FlashBoot for {avg_cold_start:.1f}s cold starts")
        print(f"   ‚Ä¢ Network storage reduces boot time significantly")  
        print(f"   ‚Ä¢ Auto-scaling handles traffic spikes")
        print(f"   ‚Ä¢ Pay-per-use eliminates idle costs")

def main():
    # Configuration
    if len(sys.argv) != 3:
        print("Usage: python test_client.py <RUNPOD_API_KEY> <ENDPOINT_ID>")
        print("\nExample:")
        print("python test_client.py your_api_key_here your_endpoint_id_here")
        sys.exit(1)
    
    api_key = sys.argv[1]
    endpoint_id = sys.argv[2]
    
    # Validate inputs
    if not api_key or len(api_key) < 10:
        print("‚ùå Invalid API key. Should be your RunPod API key.")
        sys.exit(1)
    
    if not endpoint_id or len(endpoint_id) < 10:
        print("‚ùå Invalid endpoint ID. Should be your serverless endpoint ID.")
        sys.exit(1)
    
    # Run demo
    client = RunPodDemoClient(api_key, endpoint_id)
    
    try:
        results = client.run_benchmark_suite()
        
        if results:
            print(f"\n‚úÖ Demo completed successfully!")
            print(f"üìã Results saved for presentation to dev team")
        else:
            print(f"\n‚ö†Ô∏è  Demo had issues - check logs above")
            
    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è  Demo interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Demo failed: {e}")

if __name__ == "__main__":
    main()